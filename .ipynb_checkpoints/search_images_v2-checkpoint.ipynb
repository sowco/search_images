{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5febf868",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "5febf868"
   },
   "source": [
    "\n",
    "# Демонстрационная версия поиска изображений по запросу\n",
    "\n",
    "**Задача:**\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "## Описание данных\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64833883",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "64833883",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "087a9c94",
   "metadata": {
    "id": "087a9c94"
   },
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d7639f5",
   "metadata": {
    "id": "8d7639f5",
    "outputId": "ddcdd62c-3602-4688-c6b9-013327764e8e"
   },
   "outputs": [],
   "source": [
    "# База и графики\n",
    "import os\n",
    "import re\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import notebook, tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Текст\n",
    "import spacy\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "# Нейросети\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchvision.models import ResNet18_Weights, resnet18\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fc04a2",
   "metadata": {
    "id": "42fc04a2",
    "outputId": "a4c2af35-1656-4200-97a3-db9c0caa8c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используемое устройство: cuda\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "# Проверка на доступность GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Используемое устройство: {device}\")\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a1ff4d3",
   "metadata": {
    "id": "4a1ff4d3",
    "outputId": "fd4afe4e-a656-4363-91e5-b4d3f171ab09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASE_PATH = './data/'\n",
    "TRAIN_IMAGES = os.path.join(BASE_PATH, 'train_images')\n",
    "TEST_IMAGES = os.path.join(BASE_PATH, 'test_images')\n",
    "RS = 42\n",
    "LETTERS = r'[^a-zA-Z\\s]'\n",
    "SPACES = r'([ ])\\1+'\n",
    "\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger_eng', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00eadc87",
   "metadata": {
    "id": "00eadc87",
    "outputId": "672546cf-95ec-4483-c74b-ba951555d32a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Системе не удается найти указанный путь: './data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Системе не удается найти указанный путь: './data/'"
     ]
    }
   ],
   "source": [
    "files = os.listdir(BASE_PATH)\n",
    "\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b076e",
   "metadata": {
    "id": "7c8b076e",
    "outputId": "b82bcbc6-a511-4374-e0d3-bcd03cee82e1"
   },
   "outputs": [],
   "source": [
    "# загрузка информации для обучения:\n",
    "try:\n",
    "    train_df = pd.read_csv(os.path.join(BASE_PATH, 'train_dataset.csv'))\n",
    "    print('Информация для обучения:')\n",
    "    display(train_df.head(2))\n",
    "    display(train_df.info())\n",
    "except Exception as e:\n",
    "    print('Информация для обучения недоступна:', e)\n",
    "\n",
    "# загрузка информации для тестирования:\n",
    "try:\n",
    "    test_df = pd.read_csv(os.path.join(BASE_PATH, 'test_queries.csv'), sep='|', index_col='Unnamed: 0')\n",
    "    print('Информация для тестирования:')\n",
    "    display(test_df.head(2))\n",
    "    display(test_df.info())\n",
    "except Exception as e:\n",
    "    print('Информация недоступна:', e)\n",
    "\n",
    "\n",
    "# оценка изображений на краудсорсинге\n",
    "try:\n",
    "    crowd_annotat = pd.read_csv(os.path.join(BASE_PATH, 'CrowdAnnotations.tsv'), sep='\\t',\n",
    "                                names=['image', 'query_id', 'fraction', 'conf_cnt', 'not_conf_cnt'])\n",
    "    print('Оценка изображений на краудсорсинге:')\n",
    "    display(crowd_annotat.head(2))\n",
    "    display(crowd_annotat.info())\n",
    "except Exception as e:\n",
    "    print('Информация недоступна:', e)\n",
    "\n",
    "\n",
    "# оценка изображений экспертами\n",
    "try:\n",
    "    expert_annotat = pd.read_csv(os.path.join(BASE_PATH, 'ExpertAnnotations.tsv'), sep='\\t',\n",
    "                                names=['image', 'query_id', 'exp_1', 'exp_2', 'exp_3'])\n",
    "    print('Оценка изображений экспертами:')\n",
    "    display(expert_annotat.head(2))\n",
    "    display(expert_annotat.info())\n",
    "except Exception as e:\n",
    "    print('Информация недоступна:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc463390",
   "metadata": {
    "id": "dc463390",
    "outputId": "1433c73f-f2e2-4d77-eff6-68d82ad5b8a6"
   },
   "outputs": [],
   "source": [
    "table = [train_df, test_df, crowd_annotat, expert_annotat]\n",
    "print('Посмотрим на пропуски:')\n",
    "for i in table:\n",
    "    display(i.isnull().mean().sort_values())\n",
    "\n",
    "\n",
    "print('Посмотрим на дубликаты:')\n",
    "for i in table:\n",
    "     display(i.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d7211",
   "metadata": {},
   "source": [
    "**Выводы:**\n",
    "\n",
    "1. Пропусков нет.\n",
    "2. Дубликатов полных нет.\n",
    "3. Названия колонок соотвествуют стандартам.\n",
    "4. Типы данных соответствуют данным.\n",
    "5. Текст на английском.\n",
    "6. На первый взгляд не видно критичных вопросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c9959b",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "a2c9959b"
   },
   "source": [
    "## Исследовательский анализ данных\n",
    "\n",
    "Датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. \n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "Модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab94dd56",
   "metadata": {
    "cellId": "exl6m83oldxqlu1vq1s6",
    "id": "ab94dd56"
   },
   "outputs": [],
   "source": [
    "def e_d_a(variable, name, table):\n",
    "    print(f'Смотрим статистику: {name}')\n",
    "    # Статистика\n",
    "    display(table[variable].describe())\n",
    "\n",
    "    # Гистограмма\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    table[variable].hist(bins=30, range=(max(0, table[variable].min()), table[variable].max()))\n",
    "    plt.title(f'Распределение {name}')\n",
    "    plt.xlabel(f'{name}')\n",
    "    plt.ylabel('Частота')\n",
    "    plt.show()\n",
    "\n",
    "    # Диаграмма с усами\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    table.boxplot(column=variable, vert=False, color='green', widths=0.6)\n",
    "    plt.title(f'Диаграмма межквартильного размаха для {name}')\n",
    "    plt.xlabel(f'{name}')\n",
    "    plt.yticks([])\n",
    "    plt.grid(True, linestyle='--', alpha=0.2, linewidth=1.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Описание границ\n",
    "    print('\\n', f'{name} находится в диапазоне от {table[variable].min():.2f}',\n",
    "          f'до {table[variable].max():.2f}, посмотрим как распределяются данные, видим на графике выше:'\n",
    "         )\n",
    "\n",
    "    # Вывод 75% и 98% квантилей\n",
    "    print(f'75% объектов находятся в диапазоне до {table[variable].quantile(0.75):.1f}',\n",
    "          f'\\n \\n Всего значений отличных от 0: {len(table[table[variable]>0]):.1f}.',\n",
    "          f'\\n 1Q = {table[variable].quantile(0.25):.1f},',\n",
    "          f'\\n 3Q = {table[variable].quantile(0.75):.1f},',\n",
    "          f'\\n Межквартильный размах = {(table[variable].quantile(0.75) - table[variable].quantile(0.25)):.1f},',\n",
    "         )\n",
    "\n",
    "def e_d_a_categorical(variable, name, table):\n",
    "    counts = table[variable].value_counts().sort_values(ascending=False)\n",
    "    print(f'Смотрим статистику: {name}')\n",
    "    display(table[variable].describe())\n",
    "    print('Лидеров и аутсайдеров: ')\n",
    "    display(counts)\n",
    "    if len(counts)>20:\n",
    "        print('Посмотрим на графике ТОП-10: ')\n",
    "        plt.bar(counts.head(10).index, counts.head(10).values)\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel('Количество')\n",
    "        plt.title(f'Распределение признака {name}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(counts.min()*0.9, counts.max()*1.05)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Посмотрим на графике: ')\n",
    "        plt.bar(counts.head(10).index, counts.head(10).values)\n",
    "        plt.xlabel(name)\n",
    "        plt.ylabel('Количество')\n",
    "        plt.title(f'Распределение признака {name}')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylim(counts.min()*0.9, counts.max()*1.05)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9314c82",
   "metadata": {
    "id": "f9314c82",
    "outputId": "d86deae0-d3a9-4476-d505-9a7bbc293830"
   },
   "outputs": [],
   "source": [
    "def type_col(df):\n",
    "    numeric_columns = df.select_dtypes(include='number').columns\n",
    "    text_columns = df.select_dtypes(include='object').columns\n",
    "    boolean_columns = df.select_dtypes(include='bool').columns\n",
    "    print(f'Числовые признаки: {numeric_columns.tolist()}\\n',\n",
    "          f'Логические признаки: {boolean_columns.tolist()} \\n',\n",
    "          f'Строковые признаки: {text_columns.tolist()} \\n',)\n",
    "    try:\n",
    "        display(df[numeric_columns.tolist()].describe())\n",
    "    except:\n",
    "        print('\\n')\n",
    "    try:\n",
    "        display(df[boolean_columns.tolist()].describe())\n",
    "    except:\n",
    "        print('\\n')\n",
    "    try:\n",
    "        display(df[text_columns.tolist()].describe())\n",
    "    except:\n",
    "        print('\\n')\n",
    "\n",
    "\n",
    "\n",
    "for i in table:\n",
    "    type_col(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8277e613",
   "metadata": {
    "id": "8277e613",
    "outputId": "f1f99371-a397-4bad-d9d1-6a9f66d132cf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b56b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "\n",
    "selected_rows = train_df.sample(n=num_images, random_state=RS)\n",
    "\n",
    "print('Вывод изображений и описаний к ним:')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_images, 1, figsize=(12, 4 * num_images))\n",
    "\n",
    "for i, (index, row) in enumerate(selected_rows.iterrows()):\n",
    "    image_filename = row['image']\n",
    "    image_text = train_df[train_df.image == image_filename]['query_text'].tolist()\n",
    "#     print(image_text)\n",
    "    image_path = os.path.join(TRAIN_IMAGES, image_filename)\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title('\\n'.join(image_text), fontsize=10)\n",
    "    \n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af7e7b",
   "metadata": {
    "id": "43af7e7b",
    "outputId": "f16ba369-9e8d-4cd5-ba74-c32c2035c2d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in table:\n",
    "    numeric_columns = i.select_dtypes(include='number').columns\n",
    "    text_columns = i.select_dtypes(include='object').columns\n",
    "    for j in i.columns:\n",
    "        if j in numeric_columns:\n",
    "            e_d_a(j, j, i)\n",
    "        if j in text_columns:\n",
    "            e_d_a_categorical(j, j, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a3c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "crowd_annotat['total_votes'] = crowd_annotat['conf_cnt'] + crowd_annotat['not_conf_cnt']\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "crowd_annotat['total_votes'].hist()\n",
    "plt.title(\"Общее кол-во голосов\")\n",
    "plt.xlabel(\"Количество голосов\")\n",
    "plt.ylabel(\"Частота\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5398d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "crowd_annotat['fraction'].hist(ax=axes[0])\n",
    "axes[0].set_title(\"Доля подтвердивших корректность описания\")\n",
    "\n",
    "crowd_annotat['conf_cnt'].hist(ax=axes[1])\n",
    "axes[1].set_title(\"Количество подтв. корректность\")\n",
    "\n",
    "crowd_annotat['not_conf_cnt'].hist(ax=axes[2])\n",
    "axes[2].set_title(\"Кол-во человек указавших некорректность\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62419ea",
   "metadata": {},
   "source": [
    "**Выводы:**\n",
    "1. Отзывы экспертов распределяются достаточно равномерно, почти 70% находятся в диапазоне от 1 до 2, по 4х бальной шкале.\n",
    "2. По оценкам краудсорсинга ситуация обстоит по другому: больше оценок, но при этом больше разброс.\n",
    "3. Боле 40 тысяч изображений содержит оценку 3 голосов. Большее количество голосов - уже исключение.\n",
    "4. Как видим большое количество некорректно идентифицированных аннотаций к изображениям - оправдано. Некорректных аннотаций достаточно много. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f59e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_exp(x):\n",
    "    return np.mean([x['exp_1'], x['exp_2'], x['exp_3']])\n",
    "\n",
    "expert_annotat['mean_exp'] = expert_annotat.apply(mean_exp, axis=1)\n",
    "\n",
    "train = train_df.copy()\n",
    "train_df = train_df.merge(expert_annotat, on=['image', 'query_id'], how='outer')[['image', 'mean_exp', 'query_text', 'query_id']]\n",
    "# перевод экспертные оценки из шкалы 1-4 в шкалу 0-1.\n",
    "scaler = MinMaxScaler()\n",
    "train_df['mean_exp'] = scaler.fit_transform(train_df[['mean_exp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcde118",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7a2ce",
   "metadata": {},
   "source": [
    "**Важно:**\n",
    "\n",
    "Опираться будем на объединенный набор данных оценками экспертов и краудсорсинговые оценки, что бы оставить как можно больше данных, пусть и не совсем чистых."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c5d7c",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "d99c5d7c"
   },
   "source": [
    "## Проверка данных\n",
    "\n",
    "Например, если в некоторых странах, где работает компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "У нас нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e8d6b",
   "metadata": {
    "id": "964e8d6b"
   },
   "outputs": [],
   "source": [
    "\n",
    "def lemma_clear(text):\n",
    "    lemm = nlp(text)\n",
    "    lemm = \" \".join([token.lemma_ for token in lemm])\n",
    "\n",
    "\n",
    "    return \" \".join(lemm.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd901585",
   "metadata": {},
   "source": [
    "Пишем функцию для лемматизации входного текста, что позволяет преобразовать слова в их базовые формы. Это упрощает анализ текста, так как разные формы одного и того же слова будут представлены одинаково. Кроме того, функция очищает результат от лишних пробелов, обеспечивая аккуратный вывод. Что должно повысить точность определения таких изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52fc6a",
   "metadata": {
    "id": "bf04939c"
   },
   "source": [
    "Собираем список таких слов, для анализа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c965b0",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "57c965b0"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba930931",
   "metadata": {},
   "outputs": [],
   "source": [
    "child_dict = ['child', 'baby', 'boy', 'girl', 'teenager', 'schoolboy', 'youth', 'newborn']\n",
    "\n",
    "\n",
    "def filter_child_words(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_words = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN' and (token.lemma_ in child_dict):\n",
    "            filtered_words.append(token.text.lower())\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "corpus = train_df['query_text'].apply(filter_child_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56675d74",
   "metadata": {},
   "source": [
    "Применяем фильтр, что бы убрать изображения нарушающие законодательство."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31907bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ban_word(text):\n",
    "    if isinstance(text, list):  \n",
    "        text = ' '.join(text) \n",
    "    for s in child_dict:\n",
    "        if text.find(s) > -1:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e1b99",
   "metadata": {
    "id": "784e1b99"
   },
   "outputs": [],
   "source": [
    "train_df['lem_query_text'] = corpus\n",
    "train_df['is_in_law'] = corpus.apply(is_ban_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa0a3f",
   "metadata": {
    "id": "4cfa0a3f"
   },
   "outputs": [],
   "source": [
    "def spl(text):\n",
    "    return text[:text.find('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db844dd",
   "metadata": {},
   "source": [
    "Список изображений нарушающих закон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08555cb6",
   "metadata": {
    "id": "08555cb6"
   },
   "outputs": [],
   "source": [
    "child_images = list(train_df[train_df['is_in_law']==False]['query_id'].apply(spl).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969df7f",
   "metadata": {
    "id": "e969df7f",
    "outputId": "0463db80-8070-467a-964e-32e9382075bb"
   },
   "outputs": [],
   "source": [
    "print('Смотрим количество изображений нарушающих закон и общую длину df:')\n",
    "print(len(child_images))\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9573d",
   "metadata": {
    "id": "32b9573d"
   },
   "outputs": [],
   "source": [
    "def is_not_forb(text):\n",
    "    if text in child_images:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "train_df_clear = train_df[train_df['is_in_law']]\n",
    "train_df = train_df_clear[train_df_clear['image'].apply(is_not_forb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c8e5ab",
   "metadata": {
    "id": "c2c8e5ab",
    "outputId": "29d189ae-2b61-4ea5-bff2-955f61f3492e"
   },
   "outputs": [],
   "source": [
    "print('Итого после фильтра осталось записей: ', len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eabc1c0",
   "metadata": {
    "id": "ed8001fa"
   },
   "source": [
    "**Выводы:**\n",
    "Были обработаны описания к фотографиям, если встречались слова которые указывали на нарушение закона, такие изображения были исключены из выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62cc3bf",
   "metadata": {
    "id": "c62cc3bf"
   },
   "source": [
    "## Векторизация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4c625f",
   "metadata": {
    "id": "bd4c625f",
    "outputId": "9c448094-079e-4be5-980a-48cc2e79f122"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# инициализация токенизатор, конфигурацию и модель BERT\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model_emb_txt = transformers.BertModel.from_pretrained('bert-base-uncased', config=config).to(device)\n",
    "\n",
    "\n",
    "tokenized = train_df['query_text'].progress_apply(lambda x:\n",
    "                                           tokenizer.encode(x, max_length=512,\n",
    "                                                            truncation=True, add_special_tokens=True))\n",
    "\n",
    "padded = pad_sequence([torch.as_tensor(seq) for seq in tokenized], batch_first=True)\n",
    "\n",
    "attention_mask = padded > 0\n",
    "attention_mask = attention_mask.type(torch.LongTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f6546",
   "metadata": {
    "id": "e56f6546",
    "outputId": "7012926c-1867-4435-905d-5e69baedcf13"
   },
   "outputs": [],
   "source": [
    "len(train_df['query_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211ec76",
   "metadata": {
    "id": "8211ec76",
    "outputId": "c52c1d31-217e-4712-bff0-f5d7383745f2"
   },
   "outputs": [],
   "source": [
    "padded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075736c0",
   "metadata": {
    "id": "075736c0",
    "outputId": "9bc0ef57-9e24-42ae-9754-78b0cc4f4cc3"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size * i:batch_size * (i + 1)]).to(device)\n",
    "    attention_mask_batch = torch.Tensor(attention_mask[batch_size * i:batch_size * (i + 1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model_emb_txt(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].cpu().numpy())\n",
    "\n",
    "# Обработка остатка\n",
    "if padded.shape[0] % batch_size != 0:\n",
    "    last_batch = torch.LongTensor(padded[(padded.shape[0] // batch_size) * batch_size:]).to(device)\n",
    "    attention_mask_last_batch = torch.Tensor(attention_mask[(padded.shape[0] // batch_size) * batch_size:]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        last_batch_embeddings = model_emb_txt(last_batch, attention_mask=attention_mask_last_batch)\n",
    "\n",
    "    embeddings.append(last_batch_embeddings[0][:, 0, :].cpu().numpy())\n",
    "\n",
    "text_features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffcd9a",
   "metadata": {
    "id": "22ffcd9a",
    "outputId": "fb650e1d-caef-4942-8271-f949a5b41171"
   },
   "outputs": [],
   "source": [
    "len(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c8cd9",
   "metadata": {
    "id": "519c8cd9",
    "outputId": "4e6c04e7-afa3-4a2f-d37a-9057e5df0768"
   },
   "outputs": [],
   "source": [
    "# дополнение датасета эмбедингами\n",
    "train_df['text_embeddings'] = text_features.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812a272f",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "812a272f"
   },
   "source": [
    "## Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2e00f",
   "metadata": {
    "id": "32c2e00f"
   },
   "outputs": [],
   "source": [
    "weights = ResNet18_Weights.DEFAULT\n",
    "resnet = resnet18(weights=weights).to(device)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)\n",
    "\n",
    "# оставим только свёрточные слои\n",
    "modules = list(resnet.children())[:-1]\n",
    "resnet = nn.Sequential(*modules).to(device)\n",
    "\n",
    "resnet.eval()\n",
    "\n",
    "\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_images_list = train_df['image'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105d651b",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "105d651b",
    "outputId": "4fc2846e-ed83-49c4-ee63-8aed7f56743c"
   },
   "outputs": [],
   "source": [
    "vektors = []\n",
    "\n",
    "\n",
    "for image_name in tqdm(train_images_list):\n",
    "    image = Image.open(os.path.join(TRAIN_IMAGES, image_name)).convert('RGB')\n",
    "    image = preprocess(image)\n",
    "    image = image.unsqueeze(0).to(device) \n",
    "\n",
    "    vektor = resnet(image).cpu().flatten().numpy()\n",
    "    vektors.append(vektor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c3161",
   "metadata": {
    "id": "0a5c3161"
   },
   "outputs": [],
   "source": [
    "images_vektors = np.array(vektors)\n",
    "data = pd.DataFrame({'image': train_images_list, 'image_vector': images_vektors.tolist()})\n",
    "\n",
    "train_df = train_df.merge(data, on='image', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c8688d",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "e0c8688d"
   },
   "source": [
    "## Объединение векторов\n",
    "\n",
    "Подготовим данные для обучения: объединим векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426cfd92",
   "metadata": {
    "id": "426cfd92",
    "outputId": "bedf26e4-7a43-4289-bd68-1ed42b33f36f"
   },
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af3494",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "c1af3494",
    "outputId": "54a9866c-6734-440b-f8e1-3db86551fd2a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(f'''\n",
    "    Размерность {i+1}-й пары:\n",
    "    text_embeddings: {len(train_df.iloc[i][-2])}\n",
    "    image_vector: {len(train_df.iloc[i][-1])}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336ba1e",
   "metadata": {
    "id": "3336ba1e",
    "outputId": "fcca6b9f-6c67-4f53-c9ff-8e9f5baf95fe"
   },
   "outputs": [],
   "source": [
    "train_df['concatenated_vector'] = train_df.apply(lambda row: np.concatenate([row['text_embeddings'], row['image_vector']], axis=None), axis=1)\n",
    "concatenated_vector = train_df.iloc[0, -1]\n",
    "\n",
    "if isinstance(concatenated_vector, (np.ndarray, list)):\n",
    "    print(f'Размерность объединенного вектора: {len(concatenated_vector)}')\n",
    "else:\n",
    "    print('Объединенный вектор не является массивом или списком.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669214e5",
   "metadata": {
    "id": "669214e5",
    "outputId": "cdfbf561-43fd-4781-be95-b908e84ec42c"
   },
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad344044",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "ad344044"
   },
   "source": [
    "## Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделим датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811783e",
   "metadata": {},
   "source": [
    "Для оценки качества буду использовать RMSE потому, что ее значения имеют ту же размерность, что и исходные данные, а это легче интерпретировать и более понятно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee593e37",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "ee593e37"
   },
   "outputs": [],
   "source": [
    "def rmse_score(values, predict):\n",
    "    return sqrt(mean_squared_error(values, predict))\n",
    "\n",
    "rmse_scorer = make_scorer(rmse_score)\n",
    "\n",
    "# функция для вывода результатов\n",
    "def output_results(trial):\n",
    "    print('Результаты подборы параметров:')\n",
    "    print('  RMSE:', round(trial.value, 3))\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c82925",
   "metadata": {
    "id": "b6c82925"
   },
   "outputs": [],
   "source": [
    "final_df = train_df.copy()\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=RS)\n",
    "train_indices, test_indices = next(gss.split(X=final_df.drop(columns=['mean_exp']), y=final_df['mean_exp'],\n",
    "                                             groups=final_df['image']))\n",
    "train_df, valid_df = final_df.loc[train_indices], final_df.loc[test_indices]\n",
    "\n",
    "X_train = train_df['concatenated_vector'].apply(pd.Series).values\n",
    "y_train = train_df['mean_exp']\n",
    "\n",
    "X_valid = valid_df['concatenated_vector'].apply(pd.Series).values\n",
    "y_valid = valid_df['mean_exp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2366944",
   "metadata": {},
   "source": [
    "### Baseline model\n",
    "\n",
    "константная модель, которая предсказывает среднее значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c27c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "dummy_predictions = dummy_model.predict(X_valid)\n",
    "\n",
    "rmse = rmse_score(y_valid, dummy_predictions)\n",
    "print(f'RMSE(Dummy Model): {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec8e069",
   "metadata": {},
   "source": [
    "### LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035ce5dd",
   "metadata": {},
   "source": [
    "**Регрессия** со скалированием"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da64b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_sc = train_df.copy()\n",
    "final_df_sc = final_df_sc.reset_index(drop=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "final_df_sc['mean_exp'] = scaler.fit_transform(final_df_sc[['mean_exp']])\n",
    "\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=RS)\n",
    "train_indices_sc, test_indices_sc = next(gss.split(X=final_df_sc.drop(columns=['mean_exp']), y=final_df_sc['mean_exp'],\n",
    "                                                   groups=final_df_sc['image']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df_sc, valid_df_sc = final_df_sc.loc[train_indices_sc], final_df_sc.loc[test_indices_sc]\n",
    "\n",
    "X_train_sc = train_df_sc['concatenated_vector'].apply(pd.Series).values\n",
    "y_train_sc = train_df_sc['mean_exp']\n",
    "\n",
    "X_valid_sc = valid_df_sc['concatenated_vector'].apply(pd.Series).values\n",
    "y_valid_sc = valid_df_sc['mean_exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_sc, y_train_sc)\n",
    "\n",
    "# прогнозирование на тестовых данных\n",
    "y_pred_sc = model.predict(X_valid_sc)\n",
    "\n",
    "# оценка модели\n",
    "print(f'RMSE: {rmse_score(y_valid_sc, y_pred_sc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dfca78",
   "metadata": {},
   "source": [
    "**Регрессия** без скаллера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67628990",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = train_df.copy()\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.8, random_state=RS)\n",
    "train_indices, test_indices = next(gss.split(X=final_df.drop(columns=['mean_exp']), y=final_df['mean_exp'],\n",
    "                                             groups=final_df['image']))\n",
    "train_df, valid_df = final_df.loc[train_indices], final_df.loc[test_indices]\n",
    "\n",
    "X_train = train_df['concatenated_vector'].apply(pd.Series).values\n",
    "y_train = train_df['mean_exp']\n",
    "\n",
    "X_valid = valid_df['concatenated_vector'].apply(pd.Series).values\n",
    "y_valid = valid_df['mean_exp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca2ac2",
   "metadata": {
    "id": "abca2ac2",
    "outputId": "2650212e-98b0-4a27-b15e-4b387173c1bc"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# прогнозирование на тестовых данных\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# оценка модели\n",
    "print(f'RMSE: {rmse_score(y_valid, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2a407",
   "metadata": {},
   "source": [
    "### Нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338388bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_size_1 = 4096\n",
    "hidden_size_2 = 2048\n",
    "hidden_size_3 = 1024\n",
    "hidden_size_4 = 512\n",
    "output_size = 1\n",
    "\n",
    "activation_1 = nn.ReLU()\n",
    "activation_2 = nn.Tanh()\n",
    "activation_3 = nn.ReLU()\n",
    "activation_4 = nn.LeakyReLU()\n",
    "\n",
    "drop_1 = 0.1\n",
    "drop_2 = 0.0\n",
    "drop_3 = 0.0\n",
    "drop_4 = 0.0\n",
    "\n",
    "learning_rate = 0.0001  \n",
    "n_epochs = 1000 \n",
    "batch_size = 128  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b617332",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid_tensor = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid_np = np.array(y_valid, dtype=np.float32)\n",
    "y_valid_tensor = torch.tensor(y_valid_np, dtype=torch.float32)\n",
    "input_size = X_train_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        data = self.data[idx]\n",
    "        sample = {'data': data, 'mean_exp': label}\n",
    "        return sample\n",
    "    \n",
    "dataset_train = Batch(X_train_tensor, y_train_tensor)\n",
    "dataset_test = Batch(X_valid_tensor, y_valid_tensor)\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_1, hidden_size_2, hidden_size_3, hidden_size_4, output_size,\n",
    "                 drop_1, drop_2, drop_3, drop_4,\n",
    "                 activation_1, activation_2, activation_3, activation_4):\n",
    "        super(Baseline, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size_1)\n",
    "        self.act1 = activation_1\n",
    "        self.drop1 = nn.Dropout(drop_1)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
    "        self.act2 = activation_2\n",
    "        self.drop2 = nn.Dropout(drop_2)\n",
    "\n",
    "        self.fc3 = nn.Linear(hidden_size_2, hidden_size_3)\n",
    "        self.act3 = activation_3\n",
    "        self.drop3 = nn.Dropout(drop_3)\n",
    "\n",
    "        self.fc4 = nn.Linear(hidden_size_3, hidden_size_4)\n",
    "        self.act4 = activation_4\n",
    "        self.drop4 = nn.Dropout(drop_4)\n",
    "\n",
    "        self.fc5 = nn.Linear(hidden_size_4, output_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.drop1(self.act1(self.fc1(x)))\n",
    "        x = self.drop2(self.act2(self.fc2(x)))\n",
    "        x = self.drop3(self.act3(self.fc3(x)))\n",
    "        x = self.drop4(self.act4(self.fc4(x)))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            \n",
    "class CustomEarlyStopping():\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience #сколько эпох ждать\n",
    "        self.min_delta = min_delta #разница функций потерь для активации\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif self.best_loss - val_loss > self.min_delta:  \n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif self.best_loss - val_loss < self.min_delta: \n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(f'INFO: Ранняя остановка. Счетчик: {self.counter}/{self.patience}')\n",
    "                self.early_stop = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, test_dataloader, optimizer, loss_fn, n_epochs, patience, min_delta):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    result = {\n",
    "        'rmse_train': [],\n",
    "        'rmse_test': [],\n",
    "        'best_epoch': None,\n",
    "        'stopping_epoch': None,\n",
    "        'best_model': None\n",
    "    }\n",
    "\n",
    "    early_stopping = CustomEarlyStopping(patience, min_delta)\n",
    "    best_model_state = None  \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # === Тренировка ===\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            data = batch['data'].to(device)\n",
    "            label_train = batch['mean_exp'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(data).flatten()\n",
    "            loss_value = loss_fn(predictions, label_train)\n",
    "            train_loss += loss_value.item()\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        rmse_train = sqrt(train_loss / len(train_dataloader))\n",
    "        result['rmse_train'].append(rmse_train)\n",
    "\n",
    "        # === Тестирование ===\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_dataloader:\n",
    "                data = batch['data'].to(device)\n",
    "                label_test = batch['mean_exp'].to(device)\n",
    "\n",
    "                predictions = model(data).flatten()\n",
    "                loss_value = loss_fn(predictions, label_test)\n",
    "                test_loss += loss_value.item()\n",
    "\n",
    "        rmse_test = sqrt(test_loss / len(test_dataloader))\n",
    "        result['rmse_test'].append(rmse_test)\n",
    "\n",
    "        # === Логирование каждые 10 эпох ===\n",
    "        if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
    "            print(f\"Epoch: {epoch} RMSE_train: {rmse_train:.4f} RMSE_test: {rmse_test:.4f}\")\n",
    "\n",
    "        # === Ранняя остановка ===\n",
    "        early_stopping(rmse_test)\n",
    "        if early_stopping.counter == 1: \n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            result['best_epoch'] = epoch - patience\n",
    "            result['stopping_epoch'] = epoch\n",
    "            print(f\"Early stopping at epoch {epoch}. Best RMSE_test: {min(result['rmse_test']):.4f}\")\n",
    "            break\n",
    "\n",
    "    # Сохраняем лучшую модель\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    result['best_model'] = model\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)  # Перезагружаем лучшее состояние\n",
    "    result['best_model'] = model\n",
    "\n",
    "    # Обновляем лучший регрессор\n",
    "    best_regressor = model\n",
    "\n",
    "    return result, best_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac6e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Baseline(input_size, hidden_size_1, hidden_size_2, hidden_size_3, hidden_size_4, output_size,\n",
    "                 drop_1, drop_2, drop_3, drop_4,\n",
    "                 activation_1, activation_2, activation_3, activation_4)\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=0)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fde6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, best_regressor = train(model=model,\n",
    "               train_dataloader=train_dataloader,\n",
    "               test_dataloader=test_dataloader,\n",
    "               optimizer=optimizer,\n",
    "               loss_fn=loss,\n",
    "               n_epochs=n_epochs,\n",
    "               patience=20,\n",
    "               min_delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7069719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f720998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(result['rmse_train'], color='green', label='Train RMSE')\n",
    "plt.plot(result['rmse_test'], color='blue', label='Test RMSE')\n",
    "\n",
    "\n",
    "plt.axvline(x=result['best_epoch'], color='y', linestyle='--', label='Best epoch')\n",
    "\n",
    "\n",
    "plt.axvline(x=result['stopping_epoch'], color='red', linestyle='--', label='Stopping fit')\n",
    "\n",
    "plt.title('Визуализация процесса обучения:')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caffcb0",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "5caffcb0"
   },
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520ee6a",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "9520ee6a",
    "outputId": "884f4fe2-821a-41b3-e9d0-f2764822dfb4"
   },
   "outputs": [],
   "source": [
    "test_images_list = test_df['image'].unique()\n",
    "\n",
    "test_vektors = []\n",
    "\n",
    "for image_name in tqdm(test_images_list):\n",
    "    image = Image.open(os.path.join(TEST_IMAGES, image_name)).convert('RGB')\n",
    "    image = preprocess(image)\n",
    "    image = Variable(image.unsqueeze(0)).to(device)\n",
    "\n",
    "    vektor = resnet(image).cpu().flatten().numpy() # преобразование в одномерный массив\n",
    "    test_vektors.append(vektor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e78f7",
   "metadata": {
    "id": "983e78f7"
   },
   "outputs": [],
   "source": [
    "images_test_vektors = np.array(test_vektors)\n",
    "test = pd.DataFrame({'image': test_images_list, 'image_vector': images_test_vektors.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ecf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Замена нескольких пробелов одним и нежелательные символы\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(LETTERS, ' ', txt)  \n",
    "    txt = re.sub(SPACES, r'\\1', txt) \n",
    "    return txt\n",
    "\n",
    "def stopwords_tokenize(x):\n",
    "    tokens = word_tokenize(x)  # Токенизация текста\n",
    "    tokenization = [word for word in tokens if word not in english_stopwords]\n",
    "    return ' '.join(tokenization)\n",
    "\n",
    "def clean_tokenize_text(text):\n",
    "    text = clean_text(text)\n",
    "    text = stopwords_tokenize(text)\n",
    "    return text.split()\n",
    "\n",
    "# Генерация текстового вектора\n",
    "def get_text_embedding(input_text):\n",
    "    tokenized = tokenizer.encode(input_text, max_length=512, truncation=True, add_special_tokens=True)\n",
    "    padded = pad_sequence([torch.as_tensor(tokenized)], batch_first=True)\n",
    "    attention_mask = padded > 0\n",
    "    attention_mask = attention_mask.type(torch.LongTensor).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_embedding = model_emb_txt(padded.to(device), attention_mask=attention_mask)[0][:, 0, :].cpu().numpy()\n",
    "    return text_embedding[0].tolist()\n",
    "\n",
    "# Функция тестирования\n",
    "def imag_test(query_text):\n",
    "\n",
    "    text_embedding = get_text_embedding(query_text)\n",
    "\n",
    "    test['vector'] = test['image_vector'].apply(lambda x: text_embedding + x)\n",
    "    test['vector'] = test['vector'].apply(lambda x: np.array(x, dtype=np.float32))\n",
    "\n",
    "    test_vectors = np.stack(test['vector'].to_numpy())\n",
    "    X_test_tensor = torch.tensor(test_vectors, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Предсказания модели\n",
    "    with torch.no_grad():\n",
    "        test['pred'] = best_regressor(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "    max_score = test['pred'].max()\n",
    "    path = test[test['pred'] == max_score]['image'].values[0]\n",
    "    return max_score, path\n",
    "\n",
    "# Функция вывода изображения\n",
    "def display_image_with_caption(query_text):\n",
    "    text = clean_tokenize_text(query_text)\n",
    "\n",
    "    # Проверка на запрещённые слова\n",
    "    if any(i in text for i in child_dict):\n",
    "        print(query_text)\n",
    "        print('Изображение не доступно в данном регионе')\n",
    "    else:\n",
    "        max_score, image_path = imag_test(query_text)\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        image_path = os.path.join(TEST_IMAGES, image_path)\n",
    "        img = Image.open(image_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(query_text, fontsize=12)\n",
    "        ax.axis('off')\n",
    "        plt.show()\n",
    "        print(f'Мера соответствия изображения составляет: {max_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a5eaea",
   "metadata": {
    "id": "d6a5eaea",
    "outputId": "4c4f42b8-bdf9-41f7-8dd9-e7edb11cb516",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "display_image_with_caption('Women and coctail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5731f9b",
   "metadata": {
    "id": "d5731f9b",
    "outputId": "59a89cda-e2b0-4d09-fa63-34fdfa317e89",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_image_with_caption('Dog and cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d12969",
   "metadata": {
    "id": "d7d12969",
    "outputId": "095ffefc-6aa7-4b92-d0e0-4c7bc42fda6a"
   },
   "outputs": [],
   "source": [
    "display_image_with_caption('a child on a swing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffcaa08",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "6ffcaa08"
   },
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59575423",
   "metadata": {
    "id": "59575423"
   },
   "source": [
    "Код работает, детей фильтрует, а вот качество страдает. Нужно подобрать модель которая лучше будет работать с изображениями."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (.neural_env)",
   "language": "python",
   "name": ".neural_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "778px",
    "left": "21px",
    "top": "111.125px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
